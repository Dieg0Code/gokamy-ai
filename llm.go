package gokamy

import (
	"context"
	"encoding/json"
)

// Role constants define standard message roles across different providers
const (
	RoleSystem    = "system"
	RoleDeveloper = "developer"
	RoleUser      = "user"
	RoleAssistant = "assistant"
	RoleTool      = "tool"
)

// FinishReason constants define standard reasons for completion.
const (
	FinishReasonStop      = "stop"
	FinishReasonLength    = "length"
	FinishReasonToolCalls = "tool_calls"
)

// LLMClient defines the interface for interacting with LLM providers.
type LLMClient interface {
	CreateChatCompletion(ctx context.Context, req ChatCompletionRequest) (ChatCompletionResponse, error)
}

// ChatCompletionRequest represents a unified chat completion request.
type ChatCompletionRequest struct {
	Model          string           // The model identifier to use (e.g. "gpt-4").
	Messages       []Message        // Conversational messages.
	Tools          []ToolDefinition // Optional tools available to the agent.
	Temperature    float32          // Sampling temperature.
	ResponseFormat *ResponseFormat  // Optional format for the response.
}

// Message represents a chat message with standardized fields.
type Message struct {
	Role      string     // One of RoleSystem, RoleUser, RoleAssistant, or RoleTool.
	Content   string     // The textual content of the message.
	Name      string     // Optional identifier for the sender.
	ToolCalls []ToolCall // Optional tool calls made by the assistant.
	ToolID    string     // For tool responses, references the original tool call.
}

// ToolCall represents a tool invocation request.
type ToolCall struct {
	ID   string          // Unique identifier for the tool call.
	Name string          // The name of the tool to be invoked.
	Args json.RawMessage // Arguments for the tool, encoded in JSON.
}

// ToolDefinition describes a tool's capabilities.
type ToolDefinition struct {
	Name        string          // Name of the tool.
	Description string          // A short description of what the tool does.
	Parameters  json.RawMessage // JSON Schema defining the parameters for the tool.
}

// Tool defines the interface for executable tools.
type Tool interface {
	GetDefinition() ToolDefinition
	Execute(ctx context.Context, args json.RawMessage) (interface{}, error)
}

// ResponseFormat specifies how the LLM should format its response.
type ResponseFormat struct {
	Type       string      // For example, "json_schema".
	JSONSchema *JSONSchema // The JSON schema that defines the expected response format.
}

// JSONSchema defines the structure for responses in JSON.
type JSONSchema struct {
	Name   string
	Schema json.RawMessage // The raw JSON schema.
	Strict bool            // Indicates whether strict validation is enforced.
}

// ChatCompletionResponse represents a unified response structure from the LLM.
type ChatCompletionResponse struct {
	Choices []Choice // One or more response choices.
	Usage   Usage    // Token usage statistics.
}

// Choice represents a single completion option.
type Choice struct {
	Message      Message // The message produced by the LLM.
	FinishReason string  // Reason why generation stopped (e.g. "stop", "length").
}

// Usage provides token usage statistics.
type Usage struct {
	PromptTokens     int // Number of tokens in the prompt.
	CompletionTokens int // Number of tokens generated by the model.
	TotalTokens      int // Total tokens consumed.
}
